{"cells": [{"cell_type": "code", "execution_count": 1, "id": "e4696b96-e37e-49bb-b0bd-5f2b3adb8969", "metadata": {"tags": []}, "outputs": [], "source": "import pyspark\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import cast, count, when, col, lit\nfrom pyspark.sql.types import BooleanType, IntegerType\nfrom pyspark.sql.functions import to_timestamp, to_date\nfrom pyspark.sql.functions import size, split"}, {"cell_type": "code", "execution_count": 2, "id": "1491d8dc-6251-497e-8f2f-0c1cabc4c201", "metadata": {"tags": []}, "outputs": [], "source": "import pandas as pd"}, {"cell_type": "code", "execution_count": 3, "id": "b83a1b40-dc83-476b-a397-22512cb93f2e", "metadata": {"tags": []}, "outputs": [], "source": "spark = SparkSession.builder.getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "id": "be3f1508-91b6-4cbc-8520-274f22834a61", "metadata": {"tags": []}, "outputs": [], "source": "folder_path = \"gs://yelpfrog/landing/yelp_dataset/yelp_academic_dataset_\""}, {"cell_type": "markdown", "id": "7d3635e9-dbbd-4296-9b0e-40078e2b8e42", "metadata": {}, "source": "# Business Cleaning"}, {"cell_type": "code", "execution_count": 5, "id": "978cca4b-64a8-441c-8175-794d06ddf03d", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/10/27 03:56:22 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"}], "source": "business = spark.read.json(f\"{folder_path}business.json\")"}, {"cell_type": "code", "execution_count": 6, "id": "0b688fd3-b609-408d-a58e-5bcecadb911c", "metadata": {"tags": []}, "outputs": [], "source": "# Fill in missing values in categories column with General Business\nbusiness = business.withColumn(\"categories\", when(col(\"categories\").isNull(), \"General Business\").otherwise(col(\"categories\")))"}, {"cell_type": "code", "execution_count": 7, "id": "4754ce42-079a-480f-a2df-e8d85411e9a9", "metadata": {"tags": []}, "outputs": [], "source": "# Drop unneeded columns\nbusiness = business.drop(\"attributes\", \"hours\", \"latitude\", \"longitude\")"}, {"cell_type": "code", "execution_count": 8, "id": "b4dba8c1-b877-4156-b6d8-1e296c5e7b36", "metadata": {"tags": []}, "outputs": [], "source": "# Change the is_open's datatype to Boolean\nbusiness = business.withColumn(\"is_open\", col(\"is_open\").cast(BooleanType()))"}, {"cell_type": "code", "execution_count": 9, "id": "631708e9-d901-4233-952c-9168879fcc6e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- address: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: string (nullable = true)\n |-- city: string (nullable = true)\n |-- is_open: boolean (nullable = true)\n |-- name: string (nullable = true)\n |-- postal_code: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n\n"}], "source": "business.printSchema()"}, {"cell_type": "markdown", "id": "007c0344-2291-44f7-8daf-822008d058c4", "metadata": {}, "source": "# Checkin Cleaning"}, {"cell_type": "code", "execution_count": 47, "id": "577449e3-7402-4082-b482-6705291b4924", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "checkin = spark.read.json(f\"{folder_path}checkin.json\")"}, {"cell_type": "code", "execution_count": 51, "id": "3d8009b2", "metadata": {}, "outputs": [], "source": "# Change the date's datatype to timestamp\ncheckin = checkin.withColumn(\"date\", to_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"))"}, {"cell_type": "code", "execution_count": 49, "id": "62a7a84c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- business_id: string (nullable = true)\n |-- date: timestamp (nullable = true)\n\n"}], "source": "checkin.printSchema()"}, {"cell_type": "markdown", "id": "88fc7007-266d-4a21-b66a-1a09e84b9a35", "metadata": {}, "source": "# Review Cleaning"}, {"cell_type": "code", "execution_count": 13, "id": "20be98c5-dc20-4cce-ad84-d6da38960016", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "review = spark.read.json(f\"{folder_path}review.json\")"}, {"cell_type": "code", "execution_count": 14, "id": "d60e375e-b07e-4f43-9c95-6fd7383f882d", "metadata": {"tags": []}, "outputs": [], "source": "# Change the date's datatype to date\nreview = review.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))"}, {"cell_type": "code", "execution_count": 15, "id": "9ffbdb82-c9bb-4109-a5f3-ff92ed6ebd90", "metadata": {"tags": []}, "outputs": [], "source": "# Add a word_count column\nreview = review.withColumn(\"word_count\", size(split(col(\"text\"), \" \")))"}, {"cell_type": "code", "execution_count": 16, "id": "b3fcbc34-e018-4445-bd16-2ede3c4a6914", "metadata": {"tags": []}, "outputs": [], "source": "# Drop unneeded columns\n# datetime replaces date\nreview = review.drop(\"cool\", \"funny\")"}, {"cell_type": "code", "execution_count": 17, "id": "ff3543ef-6cdb-492c-bbd0-c698c8cc4b35", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- business_id: string (nullable = true)\n |-- date: date (nullable = true)\n |-- review_id: string (nullable = true)\n |-- stars: double (nullable = true)\n |-- text: string (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n |-- word_count: integer (nullable = false)\n\n"}], "source": "review.printSchema()"}, {"cell_type": "markdown", "id": "422d1145-bc21-4fdb-b160-ad8377a72258", "metadata": {}, "source": "# Tip Cleaning"}, {"cell_type": "code", "execution_count": 18, "id": "b5a73a88-549a-4392-97e7-d9dff0bd8ca6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "tip = spark.read.json(f\"{folder_path}tip.json\")"}, {"cell_type": "code", "execution_count": 19, "id": "a10d9709-586c-425f-ae01-06d72d323646", "metadata": {}, "outputs": [], "source": "# Change the compliment_count's datatype to Integer\ntip = tip.withColumn(\"compliment_count\", col(\"compliment_count\").cast(IntegerType()))"}, {"cell_type": "code", "execution_count": 20, "id": "f396902c-aa6c-41a7-8a40-4b56a650dac9", "metadata": {}, "outputs": [], "source": "# Change the date's datatype\ntip = tip.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))"}, {"cell_type": "code", "execution_count": 21, "id": "88f65cbf-0ea1-40a1-908d-e041bac5a07e", "metadata": {}, "outputs": [], "source": "# Add a word_count column\ntip = tip.withColumn(\"word_count\", size(split(col(\"text\"), \" \")))"}, {"cell_type": "code", "execution_count": 22, "id": "e5c916bb-cf9c-408c-bd5f-16c437c6b7f6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- business_id: string (nullable = true)\n |-- compliment_count: integer (nullable = true)\n |-- date: date (nullable = true)\n |-- text: string (nullable = true)\n |-- user_id: string (nullable = true)\n |-- word_count: integer (nullable = false)\n\n"}], "source": "tip.printSchema()"}, {"cell_type": "markdown", "id": "c88ced14-9878-406f-89c6-f30461381fdb", "metadata": {}, "source": "# User Cleaning"}, {"cell_type": "code", "execution_count": null, "id": "beab2625-44ac-4434-8eb8-6c0e958cf064", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:==============================================>          (21 + 4) / 26]\r"}], "source": "user = spark.read.json(f\"{folder_path}user.json\")"}, {"cell_type": "code", "execution_count": 24, "id": "a6944d48-3d63-4a62-bfcf-6acd045e62ca", "metadata": {}, "outputs": [], "source": "# Drop unneeded columns\nuser = user.drop('compliment_cool', 'compliment_cute', 'compliment_funny', 'compliment_hot', \n                 'compliment_list', 'compliment_more', 'compliment_note', 'compliment_photos',\n                 'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'elite',\n                 'friends', 'funny')"}, {"cell_type": "code", "execution_count": 25, "id": "61f759eb-ebaf-48b1-a8a4-dfc2075cc04e", "metadata": {}, "outputs": [], "source": "# Change the yelping_since's datatype to date\nuser = user.withColumn(\"yelp_since\", to_date(col(\"yelping_since\"), \"yyyy-MM-dd\"))"}, {"cell_type": "code", "execution_count": 26, "id": "8622adc5", "metadata": {}, "outputs": [], "source": "# Change the columns_to_cast columns's datatype to Integer\n\ncolumns_to_cast = [\"average_stars\", \"fans\", \"review_count\", \"useful\"]\nuser = user.select([col(c).cast(IntegerType()).alias(c) for c in columns_to_cast])"}, {"cell_type": "code", "execution_count": 27, "id": "3790f405", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- average_stars: integer (nullable = true)\n |-- fans: integer (nullable = true)\n |-- review_count: integer (nullable = true)\n |-- useful: integer (nullable = true)\n\n"}], "source": "user.printSchema()"}, {"cell_type": "markdown", "id": "fee4cbb8", "metadata": {}, "source": "# To Parquet"}, {"cell_type": "code", "execution_count": 39, "id": "e7f33427", "metadata": {}, "outputs": [], "source": "cleaned_folder=\"gs://yelpfrog/cleaned/\""}, {"cell_type": "code", "execution_count": 40, "id": "177f9fdf", "metadata": {}, "outputs": [], "source": "cleaned_business = f\"{cleaned_folder}cleaned_business.parquet\"\ncleaned_checkin = f\"{cleaned_folder}cleaned_checkin.parquet\"\ncleaned_review = f\"{cleaned_folder}cleaned_review.parquet\"\ncleaned_tip = f\"{cleaned_folder}cleaned_tip.parquet\"\ncleaned_user = f\"{cleaned_folder}cleaned_user.parquet\""}, {"cell_type": "code", "execution_count": 41, "id": "c5405582", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "business.write.parquet(cleaned_business)"}, {"cell_type": "code", "execution_count": 53, "id": "de2f705d", "metadata": {}, "outputs": [], "source": "# checkin, review, and tip df have dates and datetimes with extra space after the :\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"}, {"cell_type": "code", "execution_count": 54, "id": "2207aba4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "checkin.write.parquet(cleaned_checkin)"}, {"cell_type": "code", "execution_count": 55, "id": "4aca82fb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "review.write.parquet(cleaned_review)"}, {"cell_type": "code", "execution_count": 56, "id": "2bb348bf", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "tip.write.parquet(cleaned_tip)"}, {"cell_type": "code", "execution_count": 57, "id": "e1bbcb30", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "user.write.parquet(cleaned_user)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}