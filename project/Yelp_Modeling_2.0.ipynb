{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d5f253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /opt/conda/miniconda3/lib/python3.11/site-packages (2023.10.1)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2.8.4rc3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2023.12.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: textblob in /opt/conda/miniconda3/lib/python3.11/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from textblob) (3.8.2)\n",
      "Requirement already satisfied: click in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      " |-- review_count_buckets: double (nullable = true)\n",
      " |-- city_index: double (nullable = false)\n",
      " |-- state_index: double (nullable = false)\n",
      " |-- encoded_review_count: vector (nullable = true)\n",
      " |-- encoded_city: vector (nullable = true)\n",
      " |-- encoded_state: vector (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "|encoded_review_count|encoded_city      |encoded_state  |sentiment_score     |features                                                   |\n",
      "+--------------------+------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "|(4,[3],[1.0])       |(1415,[186],[1.0])|(26,[1],[1.0]) |0.3680555555555556  |(1446,[3,190,1420,1445],[1.0,1.0,1.0,0.3680555555555556])  |\n",
      "|(4,[0],[1.0])       |(1415,[482],[1.0])|(26,[0],[1.0]) |0.2507575757575758  |(1446,[0,486,1419,1445],[1.0,1.0,1.0,0.2507575757575758])  |\n",
      "|(4,[2],[1.0])       |(1415,[164],[1.0])|(26,[0],[1.0]) |0.4200892857142857  |(1446,[2,168,1419,1445],[1.0,1.0,1.0,0.4200892857142857])  |\n",
      "|(4,[1],[1.0])       |(1415,[6],[1.0])  |(26,[7],[1.0]) |0.35666666666666663 |(1446,[1,10,1426,1445],[1.0,1.0,1.0,0.35666666666666663])  |\n",
      "|(4,[0],[1.0])       |(1415,[13],[1.0]) |(26,[7],[1.0]) |0.44000000000000006 |(1446,[0,17,1426,1445],[1.0,1.0,1.0,0.44000000000000006])  |\n",
      "|(4,[2],[1.0])       |(1415,[2],[1.0])  |(26,[1],[1.0]) |0.695               |(1446,[2,6,1420,1445],[1.0,1.0,1.0,0.695])                 |\n",
      "|(4,[1],[1.0])       |(1415,[31],[1.0]) |(26,[1],[1.0]) |0.48333333333333334 |(1446,[1,35,1420,1445],[1.0,1.0,1.0,0.48333333333333334])  |\n",
      "|(4,[2],[1.0])       |(1415,[1],[1.0])  |(26,[2],[1.0]) |0.215625            |(1446,[2,5,1421,1445],[1.0,1.0,1.0,0.215625])              |\n",
      "|(4,[1],[1.0])       |(1415,[176],[1.0])|(26,[13],[1.0])|0.041874999999999996|(1446,[1,180,1432,1445],[1.0,1.0,1.0,0.041874999999999996])|\n",
      "|(4,[1],[1.0])       |(1415,[130],[1.0])|(26,[0],[1.0]) |1.0                 |(1446,[1,134,1419,1445],[1.0,1.0,1.0,1.0])                 |\n",
      "|(4,[2],[1.0])       |(1415,[6],[1.0])  |(26,[7],[1.0]) |0.20049019607843138 |(1446,[2,10,1426,1445],[1.0,1.0,1.0,0.20049019607843138])  |\n",
      "|(4,[],[])           |(1415,[1],[1.0])  |(26,[2],[1.0]) |0.16944444444444445 |(1446,[5,1421,1445],[1.0,1.0,0.16944444444444445])         |\n",
      "|(4,[],[])           |(1415,[0],[1.0])  |(26,[0],[1.0]) |0.20043859649122808 |(1446,[4,1419,1445],[1.0,1.0,0.20043859649122808])         |\n",
      "|(4,[0],[1.0])       |(1415,[0],[1.0])  |(26,[0],[1.0]) |-0.10185185185185185|(1446,[0,4,1419,1445],[1.0,1.0,1.0,-0.10185185185185185])  |\n",
      "|(4,[0],[1.0])       |(1415,[4],[1.0])  |(26,[6],[1.0]) |0.011634828349944627|(1446,[0,8,1425,1445],[1.0,1.0,1.0,0.011634828349944627])  |\n",
      "|(4,[0],[1.0])       |(1415,[323],[1.0])|(26,[13],[1.0])|0.368452380952381   |(1446,[0,327,1432,1445],[1.0,1.0,1.0,0.368452380952381])   |\n",
      "|(4,[1],[1.0])       |(1415,[6],[1.0])  |(26,[7],[1.0]) |-0.29               |(1446,[1,10,1426,1445],[1.0,1.0,1.0,-0.29])                |\n",
      "|(4,[0],[1.0])       |(1415,[72],[1.0]) |(26,[4],[1.0]) |0.27082417582417584 |(1446,[0,76,1423,1445],[1.0,1.0,1.0,0.27082417582417584])  |\n",
      "|(4,[3],[1.0])       |(1415,[6],[1.0])  |(26,[7],[1.0]) |0.25033483419096625 |(1446,[3,10,1426,1445],[1.0,1.0,1.0,0.25033483419096625])  |\n",
      "|(4,[0],[1.0])       |(1415,[46],[1.0]) |(26,[9],[1.0]) |0.04814814814814814 |(1446,[0,50,1428,1445],[1.0,1.0,1.0,0.04814814814814814])  |\n",
      "+--------------------+------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      "\n",
      "name 0\n",
      "address 0\n",
      "city 0\n",
      "state 0\n",
      "postal_code 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0\n",
      "review_count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful 0\n",
      "business_stars 0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet\n",
    "%pip install textblob\n",
    "# Modules to read parquet files\n",
    "import pyarrow\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "folder_path = \"gs://yelpfrog/cleaned/cleaned_\"\n",
    "business = spark.read.parquet(f\"{folder_path}business.parquet/*\", engine='pyarrow')\n",
    "review = spark.read.parquet(f\"{folder_path}review.parquet/*\", engine='pyarrow')\n",
    "# Join review to business while rearranging columns to make it look better\n",
    "business_review = business.join(review, on='business_id').select(\n",
    "    'name', 'address', 'city', 'state', 'postal_code',\n",
    "    'text', 'review_count', 'useful', \n",
    "    business.stars.alias('business_stars')\n",
    ")\n",
    "business_review.printSchema()\n",
    "# Feature Engineering\n",
    "from pyspark.ml.feature import Bucketizer, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.types import DoubleType\n",
    "# from pyspark.sql.functions import col, isnan, when, count, udf\n",
    "# Create buckets based on percentile\n",
    "percentiles = business_review.select(\n",
    "    percentile_approx('review_count', [0.2, 0.4, 0.6, 0.8]).alias('percentiles')\n",
    ").collect()[0][0]\n",
    "# 5 buckets \n",
    "bucket_review_count = Bucketizer(splits= [0.0] + list(percentiles) + [float('inf')], \n",
    "                                     inputCol='review_count', \n",
    "                                     outputCol='review_count_buckets')\n",
    "indexer = StringIndexer(inputCols=[\"city\", \"state\"], \n",
    "                        outputCols=[\"city_index\", \"state_index\"])\n",
    "encoder = OneHotEncoder(inputCols=['review_count_buckets', 'city_index', 'state_index'], \n",
    "                        outputCols=['encoded_review_count', 'encoded_city', 'encoded_state']\n",
    "                       )\n",
    "# Create a function to perform sentiment analysis on some text\n",
    "def sentiment_analysis(text):\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    return sentiment\n",
    "# Turn function into a UDF\n",
    "sentiment_analysis_udf = udf(sentiment_analysis, DoubleType())\n",
    "from pyspark.ml import Transformer\n",
    "# Allows sentiment_score to integrate into pipeline\n",
    "class SentimentAnalysisTransformer(Transformer):\n",
    "    def __init__(self, inputCol=\"text\", outputCol=\"sentiment_score\"):\n",
    "        super().__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "    def _transform(self, df):\n",
    "        return df.withColumn(self.outputCol, sentiment_analysis_udf(df[self.inputCol]))\n",
    "sentiment_transformer = SentimentAnalysisTransformer(inputCol=\"text\", outputCol=\"sentiment_score\")\n",
    "# Want to include useful to the Vector\n",
    "assembler = VectorAssembler(inputCols=['encoded_review_count',\n",
    "                                       'encoded_city', 'encoded_state',\n",
    "                                       'sentiment_score'\n",
    "                                      ],\n",
    "                                      outputCol='features')\n",
    "# Show Features In A Copy\n",
    "# Make copy of sdf to show features while keeping original the same\n",
    "business_review_features = business_review.select(\"*\")\n",
    "business_review_features = bucket_review_count.transform(business_review_features)\n",
    "business_review_features = indexer.fit(business_review_features).transform(business_review_features)\n",
    "business_review_features = encoder.fit(business_review_features).transform(business_review_features)\n",
    "# Apply the sentiment analysis function to the text column\n",
    "# and create a new column sentiment_score\n",
    "business_review_features = business_review_features.withColumn('sentiment_score',\n",
    "                                             sentiment_analysis_udf(business_review['text'])\n",
    "                                                              )\n",
    "business_review_features = assembler.transform(business_review_features)\n",
    "business_review_features.printSchema()\n",
    "business_review_features.select(['encoded_review_count',\n",
    "                                 'encoded_city', 'encoded_state',\n",
    "                                 'sentiment_score', \n",
    "                                 'features'\n",
    "                                 ]).show(truncate=False)\n",
    "# Checking On Original Data\n",
    "business_review.printSchema()\n",
    "# Check for missing values\n",
    "for c in business_review.columns:\n",
    "    print(c, business_review.where(col(c).isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca2e4dc-d2f2-4cc4-8d42-e34dfd935a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# To Parquet\n",
    "trusted_folder=\"gs://yelpfrog/trusted/\"\n",
    "feature_engineer = f\"{trusted_folder}business_review_features2.0.parquet\"\n",
    "business_review_features.write.parquet(feature_engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "428f9916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /opt/conda/miniconda3/lib/python3.11/site-packages (2023.10.1)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2.8.4rc3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (2023.12.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/miniconda3/lib/python3.11/site-packages (from fastparquet) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: textblob in /opt/conda/miniconda3/lib/python3.11/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from textblob) (3.8.2)\n",
      "Requirement already satisfied: click in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      " |-- review_count_buckets: double (nullable = true)\n",
      " |-- city_index: double (nullable = true)\n",
      " |-- state_index: double (nullable = true)\n",
      " |-- encoded_review_count: vector (nullable = true)\n",
      " |-- encoded_city: vector (nullable = true)\n",
      " |-- encoded_state: vector (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metric [0.6862445502899804]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 280:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------+------------------+\n",
      "|name                     |business_stars|predicted_stars   |\n",
      "+-------------------------+--------------+------------------+\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.2567429275440887|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.374913610468185 |\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.820349302993229 |\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.820349302993229 |\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.7101600145977613|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.6763919114276886|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.8064800388978184|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.357268416053768 |\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.2567429275440887|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.6763919114276886|\n",
      "|1-800-GOT-JUNK? Reno     |4.5           |3.820349302993229 |\n",
      "|1-800-PACK-RAT           |1.5           |3.0176714693005744|\n",
      "|1-800-PACK-RAT           |1.5           |3.0176714693005744|\n",
      "|1-800-PACK-RAT           |1.5           |3.0080479433648613|\n",
      "|1-800-PACK-RAT           |1.5           |3.696084391314873 |\n",
      "|1-800-PACK-RAT           |1.5           |3.863531354562442 |\n",
      "|1-800-PACK-RAT           |1.5           |3.0176714693005744|\n",
      "|10 Barrel Brewing - Boise|4.0           |3.9372352096463765|\n",
      "|10 Barrel Brewing - Boise|4.0           |3.9372352096463765|\n",
      "|10 Barrel Brewing - Boise|4.0           |3.8571034390508165|\n",
      "+-------------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet\n",
    "%pip install textblob\n",
    "# Modules to read parquet files\n",
    "import pyarrow\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "# Import pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "# Import random forest\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "# Import the evaluation module\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Import the model tuning module\n",
    "from pyspark.ml.tuning import *\n",
    "import numpy as np\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "folder_path = \"gs://yelpfrog/trusted/\"\n",
    "# Modeling\n",
    "# Read business_review_features File\n",
    "business_review_features = spark.read.parquet(f\"{folder_path}business_review_features2.0.parquet/*\", engine='pyarrow')\n",
    "business_review_features.printSchema()\n",
    "# Train/Test Data\n",
    "# Split the data into 70% training and 30% test sets  \n",
    "trainingData, testData = business_review_features.randomSplit([0.7, 0.3], seed=42)\n",
    "# Random Forest\n",
    "# Create a Random Forest Estimator\n",
    "rf = RandomForestRegressor(labelCol=\"business_stars\", featuresCol=\"features\", predictionCol=\"predicted_stars\", seed=42)\n",
    "# Create a regression evaluator (to get RMSE, R2, RME, etc.)\n",
    "evaluator = RegressionEvaluator(labelCol='business_stars', predictionCol=\"predicted_stars\")\n",
    "rf_pipeline = Pipeline(stages=[rf])\n",
    "grid = ParamGridBuilder()\n",
    "\n",
    "# Build the parameter grid\n",
    "grid = grid.build()\n",
    "\n",
    "# Create the CrossValidator using the hyperparameter grid\n",
    "cv = CrossValidator(estimator=rf_pipeline, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=3)\n",
    "# .tranform would give you new columns based on pipeline specifications\n",
    "# unless we change the name in Estimator (like prediction to predicted_star)\n",
    "# rawPrediction, probability, prediction are the default ones\n",
    "transformed_sdf = rf_pipeline.fit(business_review_features).transform(business_review_features)\n",
    "# Cross Validation\n",
    "# Train the models\n",
    "all_models  = cv.fit(trainingData)\n",
    "\n",
    "# Show the average performance over the three folds\n",
    "print(f\"Average metric {all_models.avgMetrics}\")\n",
    "# Get the best model from all of the models trained\n",
    "bestModel = all_models.bestModel\n",
    "\n",
    "# Use the model 'bestModel' to predict the test set\n",
    "test_results = bestModel.transform(testData)\n",
    "# Show the prediction\n",
    "test_results.select('name','business_stars', 'predicted_stars').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "355b8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7b286eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 299:=====================================================> (38 + 1) / 39]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+--------------+------------------+\n",
      "|name                                                 |business_stars|predicted_stars   |\n",
      "+-----------------------------------------------------+--------------+------------------+\n",
      "|Big Ray's Fish Camp                                  |4.5           |3.8709845454712055|\n",
      "|Bowl of Heaven Cafe                                  |4.5           |3.7271928569935824|\n",
      "|Canyon ridge apartments                              |1.5           |3.3580215922634573|\n",
      "|Cutting Edge Salon and Boutique                      |4.5           |3.579871876137291 |\n",
      "|NYPD New York Pizza Department                       |3.5           |3.827271566552044 |\n",
      "|Napa Sonoma Grocery Company                          |4.0           |3.8348378995717547|\n",
      "|Rentz of Clearwater                                  |4.0           |3.6094076663646972|\n",
      "|Resellers Consignment Gallery                        |3.0           |3.7625523852295997|\n",
      "|The Butcher And Barkeep                              |4.0           |3.8828415452533793|\n",
      "|Charleys Philly Steaks                               |1.5           |3.135581325208399 |\n",
      "|Firestone Complete Auto Care                         |3.5           |3.533448026826727 |\n",
      "|Coco's Italian Market                                |4.0           |3.8192472518187426|\n",
      "|Microtel Inn & Suites by Wyndham Philadelphia Airport|2.0           |3.6063386411007587|\n",
      "|Ray Skillman Westside Auto Mall                      |3.5           |3.5619161658070655|\n",
      "|Sexy Grilled Cheese and Salad                        |3.0           |3.620960945508272 |\n",
      "|Spring Valley Branch YMCA                            |3.5           |3.6530306949790994|\n",
      "|Temperature Control                                  |4.0           |3.7313099431731187|\n",
      "|The Yoga Studio                                      |4.5           |3.7899054021459375|\n",
      "|Tony Roni's Pizza Plymouth Meeting                   |3.5           |3.6130806475759853|\n",
      "|El Rincon Bohemio                                    |3.5           |3.8443816415928835|\n",
      "+-----------------------------------------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a consildated list of unique businesses instead of multiple of the same ones\n",
    "consolidated_results = test_results.groupBy(\"name\", \"business_stars\").agg({\"predicted_stars\": \"avg\"})\n",
    "consolidated_results = consolidated_results.select('name','business_stars',\n",
    "                            col(\"avg(predicted_stars)\").alias(\"predicted_stars\"))\n",
    "\n",
    "consolidated_results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c5d9fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:=====================================================> (38 + 1) / 39]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|                name|business_stars|   predicted_stars|\n",
      "+--------------------+--------------+------------------+\n",
      "|1-800-GOT-JUNK? Reno|           4.5|3.6516301269485076|\n",
      "+--------------------+--------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking to make sure grouping and aggregation was correctly used\n",
    "consolidated_results.filter(consolidated_results[\"name\"] == \"1-800-GOT-JUNK? Reno\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc8abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 313:=====================================================> (38 + 1) / 39]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared:0.2190848290537395  RMSE:0.8292076311018942  MAE:0.6769763638259244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# Calculate R2, RMSE, and MAE\n",
    "r2 =evaluator.evaluate(consolidated_results,{evaluator.metricName:'r2'})\n",
    "rmse = evaluator.evaluate(consolidated_results, {evaluator.metricName: \"rmse\"})\n",
    "mae = evaluator.evaluate(consolidated_results, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "print(f\"R-squared:{r2}  RMSE:{rmse}  MAE:{mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db0501b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/25 01:28:46 WARN DAGScheduler: Broadcasting large task binary with size 1098.6 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# business_stars (actual) is columns and predicted_stars (predicted) are rows\n",
    "\n",
    "# actual: Col1 Col2      \n",
    "# Row 0 -: tn, fp \n",
    "# Row 1 +: fn, tp\n",
    "#           -   +  \n",
    "confusion_matrix = test_results.groupby('business_stars').pivot('predicted_stars').count().fillna(0).collect()\n",
    "tn = confusion_matrix[0][1]  # True Negative \n",
    "fp = confusion_matrix[0][2]  # False Positive\n",
    "fn = confusion_matrix[1][1]  # False Negative\n",
    "tp = confusion_matrix[1][2]  # True Positive\n",
    "precision = tp / (tp + fp)            \n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "f1_score = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fcd7d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf90d7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bb2b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32acdb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c877a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = all_models.bestModel.stages[-1]\n",
    "importances = best_rf_model.featureImportances\n",
    "feature_list = [\"review_count_buckets\", \n",
    "                \"city_index\", \"state_index\", \n",
    "                \"encoded_review_count\", \"encoded_city\", \"encoded_state\", \n",
    "                \"sentiment_score\"]\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(feature_list, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "potential_feature_list = [\"name\", \"address\", \"postal_code\", \"useful\"]\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(potential_feature_list, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save this as an additional file without overwriting previous one\n",
    "model_path = \"gs://yelpfrog/models/review_stars_rf_model.11-25\"\n",
    "bestModel.write().save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
